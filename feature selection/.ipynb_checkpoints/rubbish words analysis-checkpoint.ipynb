{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StoringTF(object):\n",
    "    def fit(self, vacabulary):\n",
    "        self.word_idx = vacabulary.distinct().zipWithIndex().collectAsMap()\n",
    "        self.numFeatures = len(self.word_idx)\n",
    "        \n",
    "    def indexOf(self, term):\n",
    "        \"\"\" Returns the index of the input term. \"\"\"\n",
    "        return self.word_idx[term]\n",
    "\n",
    "    def transform(self, document):\n",
    "        \"\"\"\n",
    "        Transforms the input document (list of terms) to term frequency\n",
    "        vectors, or transform the RDD of document to RDD of term\n",
    "        frequency vectors.\n",
    "        \"\"\"\n",
    "        if isinstance(document, RDD):\n",
    "            return document.map(self.transform)\n",
    "\n",
    "        freq = {}\n",
    "        for term in document:\n",
    "            i = self.indexOf(term)\n",
    "            freq[i] = freq.get(i, 0) + 1.0\n",
    "        return Vectors.sparse(self.numFeatures, freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "#from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.feature import IDF\n",
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[14] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile('hdfs://master:54310/clean'). \\\n",
    "    map(lambda line: json.loads(line)). \\\n",
    "    map(lambda doc: {'Features': doc['Text'], 'Labels': doc['Hubs']})\n",
    "\n",
    "documents = data.map(lambda x: x['Features'])\n",
    "documents.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = documents.flatMap(lambda d: d).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "storingTF = StoringTF()\n",
    "storingTF.fit(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf = storingTF.transform(documents)\n",
    "idf = IDF().fit(tf)\n",
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wc = documents.flatMap(lambda d: set(d)). \\\n",
    "    map(lambda w: (w,1)). \\\n",
    "    reduceByKey(lambda a,b: a+b). \\\n",
    "    map(lambda wc: (storingTF.indexOf(wc[0]), wc[1])). \\\n",
    "    persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552218"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.flatMap(lambda d: set(d)).map(lambda w: storingTF.indexOf(w)).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cast_sparse_vector_to_dict_and_scale(v):\n",
    "    max_v = v.toArray().max()\n",
    "    return dict([(int(i), v[int(i)] / max_v) for i in v.indices])\n",
    "\n",
    "import operator\n",
    "def order_dict_by_values(d: dict, asc = True):\n",
    "    return sorted(d.items(), key = operator.itemgetter(1), reverse= not asc)\n",
    "\n",
    "def filter_values_under_percent(vec, percent: int):\n",
    "    tfidfs = cast_sparse_vector_to_dict_and_scale(vec)\n",
    "    ordered_tfidfs = order_dict_by_values(tfidfs)\n",
    "    indexes = list(map(lambda k: k[0], ordered_tfidfs))\n",
    "    index = int(len(indexes) * percent / 100)\n",
    "    return indexes[:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 10, t: 0.9, count: 2\n",
      "p: 10, t: 0.8, count: 2\n",
      "p: 10, t: 0.7, count: 2\n",
      "p: 10, t: 0.6, count: 8\n",
      "p: 10, t: 0.5, count: 47\n",
      "p: 10, t: 0.4, count: 94\n",
      "p: 10, t: 0.3, count: 130\n",
      "p: 10, t: 0.2, count: 179\n",
      "p: 10, t: 0.1, count: 256\n",
      "p: 20, t: 0.9, count: 2\n",
      "p: 20, t: 0.8, count: 2\n",
      "p: 20, t: 0.7, count: 17\n",
      "p: 20, t: 0.6, count: 119\n",
      "p: 20, t: 0.5, count: 229\n",
      "p: 20, t: 0.4, count: 321\n",
      "p: 20, t: 0.3, count: 410\n",
      "p: 20, t: 0.2, count: 508\n",
      "p: 20, t: 0.1, count: 681\n",
      "p: 30, t: 0.9, count: 69\n",
      "p: 30, t: 0.8, count: 77\n",
      "p: 30, t: 0.7, count: 213\n",
      "p: 30, t: 0.6, count: 423\n",
      "p: 30, t: 0.5, count: 570\n",
      "p: 30, t: 0.4, count: 792\n",
      "p: 30, t: 0.3, count: 964\n",
      "p: 30, t: 0.2, count: 1181\n",
      "p: 30, t: 0.1, count: 1576\n",
      "p: 40, t: 0.9, count: 433\n",
      "p: 40, t: 0.8, count: 510\n",
      "p: 40, t: 0.7, count: 859\n",
      "p: 40, t: 0.6, count: 1121\n",
      "p: 40, t: 0.5, count: 1349\n",
      "p: 40, t: 0.4, count: 1714\n",
      "p: 40, t: 0.3, count: 2051\n",
      "p: 40, t: 0.2, count: 2439\n",
      "p: 40, t: 0.1, count: 3257\n",
      "p: 50, t: 0.9, count: 1064\n",
      "p: 50, t: 0.8, count: 1392\n",
      "p: 50, t: 0.7, count: 1908\n",
      "p: 50, t: 0.6, count: 2322\n",
      "p: 50, t: 0.5, count: 2688\n",
      "p: 50, t: 0.4, count: 3458\n",
      "p: 50, t: 0.3, count: 4177\n",
      "p: 50, t: 0.2, count: 5047\n",
      "p: 50, t: 0.1, count: 7146\n",
      "p: 60, t: 0.9, count: 3074\n",
      "p: 60, t: 0.8, count: 3863\n",
      "p: 60, t: 0.7, count: 4579\n",
      "p: 60, t: 0.6, count: 5246\n",
      "p: 60, t: 0.5, count: 5932\n",
      "p: 60, t: 0.4, count: 7769\n",
      "p: 60, t: 0.3, count: 9618\n",
      "p: 60, t: 0.2, count: 11601\n",
      "p: 60, t: 0.1, count: 16734\n"
     ]
    }
   ],
   "source": [
    "experiments = {}\n",
    "for p in [10, 20, 30, 40, 50, 60]:\n",
    "    excluded = tfidf.flatMap(lambda vec: filter_values_under_percent(vec, p)). \\\n",
    "        map(lambda i: (i, 1)). \\\n",
    "        reduceByKey(lambda a,b: a+b).persist()\n",
    "    stat = wc.join(excluded).map(lambda s: (s[0], s[1][1]/s[1][0])).persist()\n",
    "    experiment = {}\n",
    "    for t in [.9, .8, .7, .6, .5, .4, .3, .2, .1]:\n",
    "        excluded_count = stat.filter(lambda s: s[1] > t).count()\n",
    "        experiment[t] = excluded_count\n",
    "        print(\"p: {0}, t: {1}, count: {2}\".format(p, t, excluded_count))\n",
    "    stat.unpersist()\n",
    "    excluded.unpersist()\n",
    "    experiments[p] = experiment    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>30</th>\n",
       "      <th>40</th>\n",
       "      <th>50</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>256</td>\n",
       "      <td>681</td>\n",
       "      <td>1576</td>\n",
       "      <td>3257</td>\n",
       "      <td>7146</td>\n",
       "      <td>16734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>179</td>\n",
       "      <td>508</td>\n",
       "      <td>1181</td>\n",
       "      <td>2439</td>\n",
       "      <td>5047</td>\n",
       "      <td>11601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>130</td>\n",
       "      <td>410</td>\n",
       "      <td>964</td>\n",
       "      <td>2051</td>\n",
       "      <td>4177</td>\n",
       "      <td>9618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>94</td>\n",
       "      <td>321</td>\n",
       "      <td>792</td>\n",
       "      <td>1714</td>\n",
       "      <td>3458</td>\n",
       "      <td>7769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>47</td>\n",
       "      <td>229</td>\n",
       "      <td>570</td>\n",
       "      <td>1349</td>\n",
       "      <td>2688</td>\n",
       "      <td>5932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>8</td>\n",
       "      <td>119</td>\n",
       "      <td>423</td>\n",
       "      <td>1121</td>\n",
       "      <td>2322</td>\n",
       "      <td>5246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>213</td>\n",
       "      <td>859</td>\n",
       "      <td>1908</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>77</td>\n",
       "      <td>510</td>\n",
       "      <td>1392</td>\n",
       "      <td>3863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "      <td>433</td>\n",
       "      <td>1064</td>\n",
       "      <td>3074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      10   20    30    40    50     60\n",
       "0.1  256  681  1576  3257  7146  16734\n",
       "0.2  179  508  1181  2439  5047  11601\n",
       "0.3  130  410   964  2051  4177   9618\n",
       "0.4   94  321   792  1714  3458   7769\n",
       "0.5   47  229   570  1349  2688   5932\n",
       "0.6    8  119   423  1121  2322   5246\n",
       "0.7    2   17   213   859  1908   4579\n",
       "0.8    2    2    77   510  1392   3863\n",
       "0.9    2    2    69   433  1064   3074"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exclude_words_bellow_threshold(word_tfidfs, t: float):\n",
    "    tfidfs = cast_sparse_vector_to_dict_and_scale(vec)\n",
    "    return [i_tfidf[0] for i_tfidf in tfidfs.items() if i_tfidf[1] < t]\n",
    "\n",
    "experiments_2 = {}\n",
    "for p in [.5, .4, .3, .2, .1, .05, .01, .005]:\n",
    "    excluded = tfidf.flatMap(lambda vec: filter_values_under_percent(vec, p)). \\\n",
    "        map(lambda i: (i, 1)). \\\n",
    "        reduceByKey(lambda a,b: a+b).persist()\n",
    "    stat = wc.join(excluded).map(lambda s: (s[0], s[1][1]/s[1][0])).persist()\n",
    "    experiment = {}\n",
    "    for t in [.9, .8, .7, .6, .5, .4, .3, .2, .1]:\n",
    "        excluded_count = stat.filter(lambda s: s[1] > t).count()\n",
    "        experiment[t] = excluded_count\n",
    "        print(\"p: {0}, t: {1}, count: {2}\".format(p, t, excluded_count))\n",
    "    stat.unpersist()\n",
    "    excluded.unpersist()\n",
    "    experiments_2[p] = experiment    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
