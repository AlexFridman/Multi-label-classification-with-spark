{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import RDD\n",
    "import json\n",
    "#from pyspark.mllib.feature import HashingTF\n",
    "from pyspark.mllib.feature import IDF\n",
    "import numpy as np\n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StoringTF(object):\n",
    "    def fit(self, vacabulary):\n",
    "        self.word_idx = vacabulary.distinct().zipWithIndex().collectAsMap()\n",
    "        self.numFeatures = len(self.word_idx)\n",
    "        \n",
    "    def indexOf(self, term):\n",
    "        \"\"\" Returns the index of the input term. \"\"\"\n",
    "        return self.word_idx[term]\n",
    "\n",
    "    def transform(self, document):\n",
    "        \"\"\"\n",
    "        Transforms the input document (list of terms) to term frequency\n",
    "        vectors, or transform the RDD of document to RDD of term\n",
    "        frequency vectors.\n",
    "        \"\"\"\n",
    "        if isinstance(document, RDD):\n",
    "            return document.map(self.transform)\n",
    "\n",
    "        freq = {}\n",
    "        for term in document:\n",
    "            i = self.indexOf(term)\n",
    "            freq[i] = freq.get(i, 0) + 1.0\n",
    "        return Vectors.sparse(self.numFeatures, freq.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[145] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = sc.textFile('hdfs://master:54310/exp_2/ml_data_without_urls'). \\\n",
    "    map(lambda line: json.loads(line))\n",
    "    \n",
    "documents = data.map(lambda x: x['Features'])\n",
    "documents.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = documents.flatMap(lambda d: d).distinct()\n",
    "\n",
    "storingTF = StoringTF()\n",
    "storingTF.fit(vocabulary)\n",
    "\n",
    "tf = storingTF.transform(documents)\n",
    "idf = IDF().fit(tf)\n",
    "tfidf = idf.transform(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[165] at mapPartitions at PythonMLLibAPI.scala:1480"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wc = documents.flatMap(lambda d: set(d)). \\\n",
    "    map(lambda w: (w,1)). \\\n",
    "    reduceByKey(lambda a,b: a+b). \\\n",
    "    map(lambda wc: (storingTF.indexOf(wc[0]), wc[1])). \\\n",
    "    persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102514"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.flatMap(lambda d: set(d)).map(lambda w: storingTF.indexOf(w)).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cast_sparse_vector_to_dict_and_scale(v):\n",
    "    max_v = v.values.max()\n",
    "    return dict([(int(i), v[int(i)] / max_v) for i in v.indices])\n",
    "\n",
    "import operator\n",
    "def order_dict_by_values(d: dict, asc = True):\n",
    "    return sorted(d.items(), key = operator.itemgetter(1), reverse= not asc)\n",
    "\n",
    "def filter_values_under_percent(vec, percent: int):\n",
    "    tfidfs = cast_sparse_vector_to_dict_and_scale(vec)\n",
    "    ordered_tfidfs = order_dict_by_values(tfidfs)\n",
    "    indexes = list(map(lambda k: k[0], ordered_tfidfs))\n",
    "    index = int(len(indexes) * percent / 100)\n",
    "    return indexes[:index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exclude_words_bellow_threshold(vec, t: float):\n",
    "    tfidfs = cast_sparse_vector_to_dict_and_scale(vec)\n",
    "    return [i_tfidf[0] for i_tfidf in tfidfs.items() if i_tfidf[1] < t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 0.9, t: 0.99, count: 54478\n",
      "p: 0.9, t: 0.95, count: 54769\n",
      "p: 0.9, t: 0.9, count: 55131\n",
      "p: 0.9, t: 0.8, count: 56137\n",
      "p: 0.9, t: 0.7, count: 58351\n",
      "p: 0.9, t: 0.6, count: 62242\n",
      "p: 0.9, t: 0.5, count: 63994\n",
      "p: 0.9, t: 0.4, count: 68881\n",
      "p: 0.9, t: 0.3, count: 73661\n",
      "p: 0.9, t: 0.2, count: 78436\n",
      "p: 0.9, t: 0.1, count: 85499\n",
      "p: 0.8, t: 0.99, count: 53935\n",
      "p: 0.8, t: 0.95, count: 54273\n",
      "p: 0.8, t: 0.9, count: 54652\n",
      "p: 0.8, t: 0.8, count: 55712\n",
      "p: 0.8, t: 0.7, count: 57933\n",
      "p: 0.8, t: 0.6, count: 61793\n",
      "p: 0.8, t: 0.5, count: 63527\n",
      "p: 0.8, t: 0.4, count: 68556\n",
      "p: 0.8, t: 0.3, count: 73398\n",
      "p: 0.8, t: 0.2, count: 78164\n",
      "p: 0.8, t: 0.1, count: 85265\n",
      "p: 0.7, t: 0.99, count: 53206\n",
      "p: 0.7, t: 0.95, count: 53548\n",
      "p: 0.7, t: 0.9, count: 53998\n",
      "p: 0.7, t: 0.8, count: 55077\n",
      "p: 0.7, t: 0.7, count: 57278\n",
      "p: 0.7, t: 0.6, count: 61145\n",
      "p: 0.7, t: 0.5, count: 62887\n",
      "p: 0.7, t: 0.4, count: 68049\n",
      "p: 0.7, t: 0.3, count: 72948\n",
      "p: 0.7, t: 0.2, count: 77744\n",
      "p: 0.7, t: 0.1, count: 84898\n",
      "p: 0.6, t: 0.99, count: 52195\n",
      "p: 0.6, t: 0.95, count: 52531\n",
      "p: 0.6, t: 0.9, count: 53024\n",
      "p: 0.6, t: 0.8, count: 54137\n",
      "p: 0.6, t: 0.7, count: 56361\n",
      "p: 0.6, t: 0.6, count: 60197\n",
      "p: 0.6, t: 0.5, count: 61914\n",
      "p: 0.6, t: 0.4, count: 67316\n",
      "p: 0.6, t: 0.3, count: 72246\n",
      "p: 0.6, t: 0.2, count: 77072\n",
      "p: 0.6, t: 0.1, count: 84365\n",
      "p: 0.5, t: 0.99, count: 50653\n",
      "p: 0.5, t: 0.95, count: 50940\n",
      "p: 0.5, t: 0.9, count: 51440\n",
      "p: 0.5, t: 0.8, count: 52584\n",
      "p: 0.5, t: 0.7, count: 54806\n",
      "p: 0.5, t: 0.6, count: 58550\n",
      "p: 0.5, t: 0.5, count: 60260\n",
      "p: 0.5, t: 0.4, count: 66076\n",
      "p: 0.5, t: 0.3, count: 71085\n",
      "p: 0.5, t: 0.2, count: 75947\n",
      "p: 0.5, t: 0.1, count: 83335\n",
      "p: 0.4, t: 0.99, count: 48546\n",
      "p: 0.4, t: 0.95, count: 48747\n",
      "p: 0.4, t: 0.9, count: 49174\n",
      "p: 0.4, t: 0.8, count: 50397\n",
      "p: 0.4, t: 0.7, count: 52555\n",
      "p: 0.4, t: 0.6, count: 56179\n",
      "p: 0.4, t: 0.5, count: 57887\n",
      "p: 0.4, t: 0.4, count: 64228\n",
      "p: 0.4, t: 0.3, count: 69390\n",
      "p: 0.4, t: 0.2, count: 74223\n",
      "p: 0.4, t: 0.1, count: 81777\n",
      "p: 0.3, t: 0.99, count: 45262\n",
      "p: 0.3, t: 0.95, count: 45366\n",
      "p: 0.3, t: 0.9, count: 45665\n",
      "p: 0.3, t: 0.8, count: 46772\n",
      "p: 0.3, t: 0.7, count: 48900\n",
      "p: 0.3, t: 0.6, count: 52394\n",
      "p: 0.3, t: 0.5, count: 53983\n",
      "p: 0.3, t: 0.4, count: 61099\n",
      "p: 0.3, t: 0.3, count: 66412\n",
      "p: 0.3, t: 0.2, count: 71241\n",
      "p: 0.3, t: 0.1, count: 78965\n",
      "p: 0.2, t: 0.99, count: 39659\n",
      "p: 0.2, t: 0.95, count: 39723\n",
      "p: 0.2, t: 0.9, count: 39919\n",
      "p: 0.2, t: 0.8, count: 40673\n",
      "p: 0.2, t: 0.7, count: 42419\n",
      "p: 0.2, t: 0.6, count: 45476\n",
      "p: 0.2, t: 0.5, count: 46992\n",
      "p: 0.2, t: 0.4, count: 54843\n",
      "p: 0.2, t: 0.3, count: 60306\n",
      "p: 0.2, t: 0.2, count: 65021\n",
      "p: 0.2, t: 0.1, count: 72761\n",
      "p: 0.1, t: 0.99, count: 28200\n",
      "p: 0.1, t: 0.95, count: 28247\n",
      "p: 0.1, t: 0.9, count: 28377\n",
      "p: 0.1, t: 0.8, count: 28872\n",
      "p: 0.1, t: 0.7, count: 29952\n",
      "p: 0.1, t: 0.6, count: 31834\n",
      "p: 0.1, t: 0.5, count: 32824\n",
      "p: 0.1, t: 0.4, count: 40154\n",
      "p: 0.1, t: 0.3, count: 45095\n",
      "p: 0.1, t: 0.2, count: 49362\n",
      "p: 0.1, t: 0.1, count: 56258\n",
      "p: 0.05, t: 0.99, count: 17532\n",
      "p: 0.05, t: 0.95, count: 17562\n",
      "p: 0.05, t: 0.9, count: 17635\n",
      "p: 0.05, t: 0.8, count: 17941\n",
      "p: 0.05, t: 0.7, count: 18613\n",
      "p: 0.05, t: 0.6, count: 19784\n",
      "p: 0.05, t: 0.5, count: 20322\n",
      "p: 0.05, t: 0.4, count: 25343\n",
      "p: 0.05, t: 0.3, count: 28662\n",
      "p: 0.05, t: 0.2, count: 31489\n",
      "p: 0.05, t: 0.1, count: 36585\n",
      "p: 0.01, t: 0.99, count: 3432\n",
      "p: 0.01, t: 0.95, count: 3437\n",
      "p: 0.01, t: 0.9, count: 3451\n",
      "p: 0.01, t: 0.8, count: 3518\n",
      "p: 0.01, t: 0.7, count: 3644\n",
      "p: 0.01, t: 0.6, count: 3896\n",
      "p: 0.01, t: 0.5, count: 3997\n",
      "p: 0.01, t: 0.4, count: 5383\n",
      "p: 0.01, t: 0.3, count: 6224\n",
      "p: 0.01, t: 0.2, count: 6812\n",
      "p: 0.01, t: 0.1, count: 7983\n",
      "p: 0.005, t: 0.99, count: 1279\n",
      "p: 0.005, t: 0.95, count: 1283\n",
      "p: 0.005, t: 0.9, count: 1290\n",
      "p: 0.005, t: 0.8, count: 1310\n",
      "p: 0.005, t: 0.7, count: 1358\n",
      "p: 0.005, t: 0.6, count: 1465\n",
      "p: 0.005, t: 0.5, count: 1522\n",
      "p: 0.005, t: 0.4, count: 2158\n",
      "p: 0.005, t: 0.3, count: 2572\n",
      "p: 0.005, t: 0.2, count: 2872\n",
      "p: 0.005, t: 0.1, count: 3445\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.005</th>\n",
       "      <th>0.01</th>\n",
       "      <th>0.05</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>0.3</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.7</th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.10</th>\n",
       "      <td>3445</td>\n",
       "      <td>7983</td>\n",
       "      <td>36585</td>\n",
       "      <td>56258</td>\n",
       "      <td>72761</td>\n",
       "      <td>78965</td>\n",
       "      <td>81777</td>\n",
       "      <td>83335</td>\n",
       "      <td>84365</td>\n",
       "      <td>84898</td>\n",
       "      <td>85265</td>\n",
       "      <td>85499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.20</th>\n",
       "      <td>2872</td>\n",
       "      <td>6812</td>\n",
       "      <td>31489</td>\n",
       "      <td>49362</td>\n",
       "      <td>65021</td>\n",
       "      <td>71241</td>\n",
       "      <td>74223</td>\n",
       "      <td>75947</td>\n",
       "      <td>77072</td>\n",
       "      <td>77744</td>\n",
       "      <td>78164</td>\n",
       "      <td>78436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.30</th>\n",
       "      <td>2572</td>\n",
       "      <td>6224</td>\n",
       "      <td>28662</td>\n",
       "      <td>45095</td>\n",
       "      <td>60306</td>\n",
       "      <td>66412</td>\n",
       "      <td>69390</td>\n",
       "      <td>71085</td>\n",
       "      <td>72246</td>\n",
       "      <td>72948</td>\n",
       "      <td>73398</td>\n",
       "      <td>73661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.40</th>\n",
       "      <td>2158</td>\n",
       "      <td>5383</td>\n",
       "      <td>25343</td>\n",
       "      <td>40154</td>\n",
       "      <td>54843</td>\n",
       "      <td>61099</td>\n",
       "      <td>64228</td>\n",
       "      <td>66076</td>\n",
       "      <td>67316</td>\n",
       "      <td>68049</td>\n",
       "      <td>68556</td>\n",
       "      <td>68881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.50</th>\n",
       "      <td>1522</td>\n",
       "      <td>3997</td>\n",
       "      <td>20322</td>\n",
       "      <td>32824</td>\n",
       "      <td>46992</td>\n",
       "      <td>53983</td>\n",
       "      <td>57887</td>\n",
       "      <td>60260</td>\n",
       "      <td>61914</td>\n",
       "      <td>62887</td>\n",
       "      <td>63527</td>\n",
       "      <td>63994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.60</th>\n",
       "      <td>1465</td>\n",
       "      <td>3896</td>\n",
       "      <td>19784</td>\n",
       "      <td>31834</td>\n",
       "      <td>45476</td>\n",
       "      <td>52394</td>\n",
       "      <td>56179</td>\n",
       "      <td>58550</td>\n",
       "      <td>60197</td>\n",
       "      <td>61145</td>\n",
       "      <td>61793</td>\n",
       "      <td>62242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.70</th>\n",
       "      <td>1358</td>\n",
       "      <td>3644</td>\n",
       "      <td>18613</td>\n",
       "      <td>29952</td>\n",
       "      <td>42419</td>\n",
       "      <td>48900</td>\n",
       "      <td>52555</td>\n",
       "      <td>54806</td>\n",
       "      <td>56361</td>\n",
       "      <td>57278</td>\n",
       "      <td>57933</td>\n",
       "      <td>58351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.80</th>\n",
       "      <td>1310</td>\n",
       "      <td>3518</td>\n",
       "      <td>17941</td>\n",
       "      <td>28872</td>\n",
       "      <td>40673</td>\n",
       "      <td>46772</td>\n",
       "      <td>50397</td>\n",
       "      <td>52584</td>\n",
       "      <td>54137</td>\n",
       "      <td>55077</td>\n",
       "      <td>55712</td>\n",
       "      <td>56137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.90</th>\n",
       "      <td>1290</td>\n",
       "      <td>3451</td>\n",
       "      <td>17635</td>\n",
       "      <td>28377</td>\n",
       "      <td>39919</td>\n",
       "      <td>45665</td>\n",
       "      <td>49174</td>\n",
       "      <td>51440</td>\n",
       "      <td>53024</td>\n",
       "      <td>53998</td>\n",
       "      <td>54652</td>\n",
       "      <td>55131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.95</th>\n",
       "      <td>1283</td>\n",
       "      <td>3437</td>\n",
       "      <td>17562</td>\n",
       "      <td>28247</td>\n",
       "      <td>39723</td>\n",
       "      <td>45366</td>\n",
       "      <td>48747</td>\n",
       "      <td>50940</td>\n",
       "      <td>52531</td>\n",
       "      <td>53548</td>\n",
       "      <td>54273</td>\n",
       "      <td>54769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.99</th>\n",
       "      <td>1279</td>\n",
       "      <td>3432</td>\n",
       "      <td>17532</td>\n",
       "      <td>28200</td>\n",
       "      <td>39659</td>\n",
       "      <td>45262</td>\n",
       "      <td>48546</td>\n",
       "      <td>50653</td>\n",
       "      <td>52195</td>\n",
       "      <td>53206</td>\n",
       "      <td>53935</td>\n",
       "      <td>54478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0.005  0.010  0.050  0.100  0.200  0.300  0.400  0.500  0.600  0.700  \\\n",
       "0.10   3445   7983  36585  56258  72761  78965  81777  83335  84365  84898   \n",
       "0.20   2872   6812  31489  49362  65021  71241  74223  75947  77072  77744   \n",
       "0.30   2572   6224  28662  45095  60306  66412  69390  71085  72246  72948   \n",
       "0.40   2158   5383  25343  40154  54843  61099  64228  66076  67316  68049   \n",
       "0.50   1522   3997  20322  32824  46992  53983  57887  60260  61914  62887   \n",
       "0.60   1465   3896  19784  31834  45476  52394  56179  58550  60197  61145   \n",
       "0.70   1358   3644  18613  29952  42419  48900  52555  54806  56361  57278   \n",
       "0.80   1310   3518  17941  28872  40673  46772  50397  52584  54137  55077   \n",
       "0.90   1290   3451  17635  28377  39919  45665  49174  51440  53024  53998   \n",
       "0.95   1283   3437  17562  28247  39723  45366  48747  50940  52531  53548   \n",
       "0.99   1279   3432  17532  28200  39659  45262  48546  50653  52195  53206   \n",
       "\n",
       "      0.800  0.900  \n",
       "0.10  85265  85499  \n",
       "0.20  78164  78436  \n",
       "0.30  73398  73661  \n",
       "0.40  68556  68881  \n",
       "0.50  63527  63994  \n",
       "0.60  61793  62242  \n",
       "0.70  57933  58351  \n",
       "0.80  55712  56137  \n",
       "0.90  54652  55131  \n",
       "0.95  54273  54769  \n",
       "0.99  53935  54478  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments_2 = {}\n",
    "for p in [.9, .8, .7, .6, .5, .4, .3, .2, .1, .05, .01, .005]:\n",
    "    excluded = tfidf_1st.flatMap(lambda vec: exclude_words_bellow_threshold(vec, p)). \\\n",
    "        map(lambda i: (i, 1)). \\\n",
    "        reduceByKey(lambda a,b: a+b)\n",
    "    excluded.cache()\n",
    "    stat = wc.join(excluded).map(lambda s: (s[0], s[1][1]/s[1][0]))\n",
    "    stat.cache()\n",
    "    experiment = {}\n",
    "    for t in [.99, .95, .9, .8, .7, .6, .5, .4, .3, .2, .1]:\n",
    "        excluded_count = stat.filter(lambda s: s[1] > t).count()\n",
    "        experiment[t] = excluded_count\n",
    "        print(\"p: {0}, t: {1}, count: {2}\".format(p, t, excluded_count))\n",
    "    stat.unpersist()\n",
    "    excluded.unpersist()\n",
    "    experiments_2[p] = experiment    \n",
    "pd.DataFrame(experiments_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102514"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "102514"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_word = dict([(idx,w) for w,idx in storingTF.word_idx.items()])\n",
    "len(idx_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excluded = tfidf.flatMap(lambda vec: exclude_words_bellow_threshold(vec, .3)). \\\n",
    "        map(lambda i: (i, 1)). \\\n",
    "        reduceByKey(lambda a,b: a+b)\n",
    "stat = wc.join(excluded).map(lambda s: (s[0], s[1][1] == [1][0]))\n",
    "excluded_words = stat.filter(lambda s: s[1] > 0.6).map(lambda x: idx_word[x[0]]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14313"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(excluded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "set_of_excluded_words = set(excluded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18915"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set_of_excluded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exclude_words(doc: dict, excluded):\n",
    "    doc['Features'] = [w for w in doc['Features'] if w not in excluded]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "339.97511553812757"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: exclude_words(x, set_of_excluded_words)). \\\n",
    "    map(lambda x: len(x['Features'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "340.6226629787831"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: len(x['Features'])).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stage.map(json.dumps). \\\n",
    "    repartition(6). \\\n",
    "    saveAsTextFile('hdfs://master:54310/excluded_fin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
