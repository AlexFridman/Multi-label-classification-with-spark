{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = sc.textFile('hdfs://master:54310/clean_ml'). \\\n",
    "    map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "excluding_words = set(data.flatMap(lambda doc: set(doc['Features'])). \\\n",
    "    map(lambda w: (w, 1)). \\\n",
    "    reduceByKey(int.__add__). \\\n",
    "    filter(lambda wc: wc[1] == 1). \\\n",
    "    collectAsMap().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "excluding_words_br = sc.broadcast(excluding_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "264750"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(excluding_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "524889"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.flatMap(lambda doc: set(doc['Features'])).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exclude_words(doc: dict):\n",
    "    doc['Features'] = [w for w in doc['Features']\n",
    "                       if w not in excluding_words_br.value]\n",
    "    return doc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_data = data.map(exclude_words).filter(lambda x: x['Features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_idx = clean_data.flatMap(lambda doc: doc['Features']). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()\n",
    "label_idx = clean_data.flatMap(lambda doc: doc['Labels']). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_idx_br = sc.broadcast(word_idx)\n",
    "label_idx_br = sc.broadcast(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_data(doc: dict):\n",
    "    doc['Features'] = [word_idx_br.value[w] for w in doc['Features']]\n",
    "    doc['Labels'] = [label_idx_br.value[l] for l in doc['Labels']]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vect_data = clean_data.map(vectorize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def divide_by_total_count(word_count: dict):\n",
    "    val_sum = sum(word_count.values())\n",
    "    for k,v in word_count.items():\n",
    "        word_count[k] = v/val_sum\n",
    "    return word_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sc.addPyFile('/home/hadoop/spark/lib/sparse.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sparse import sparse_vector\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[19] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "probs = vect_data.map(lambda doc: (doc['Labels'], Counter(doc['Features']))). \\\n",
    "    flatMap(lambda x: [(h, x[1]) for h in x[0]]). \\\n",
    "    reduceByKey(lambda a,b: a+b). \\\n",
    "    map(lambda x: (x[0], divide_by_total_count(dict(x[1])))). \\\n",
    "    map(lambda x: (x[0], sparse_vector(list(x[1].items()), length=num_features, dtype=float))). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probs_br = sc.broadcast(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_word_idx = dict([(v, k) for k,v in word_idx.items()])\n",
    "inv_label_idx = dict([(v, k) for k,v in label_idx.items()])\n",
    "inv_word_idx_br = sc.broadcast(inv_word_idx)\n",
    "inv_label_idx_br = sc.broadcast(inv_label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unvectorize_data(doc: dict):\n",
    "    doc['Label'] = inv_label_idx_br.value[doc['Label']]\n",
    "    doc['Features'] = [inv_word_idx_br.value[key] for key in doc['Features']]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "def calc_log_prob(label: int, words: list):\n",
    "    word_probs = probs_br.value[label]\n",
    "    return sum([log(word_probs[word]) for word in set(words)]) \n",
    "\n",
    "def choose_max_prob_hub(doc: list, hubs: list):\n",
    "    if len(hubs) == 1:\n",
    "        return hubs[0]\n",
    "    else:\n",
    "        return max([(h, calc_log_prob(h, doc)) for h in hubs], key=lambda x: x[1])[0]\n",
    "    \n",
    "vect_data.map(lambda doc: {'Id': doc['Id'],\n",
    "                     'Features': doc['Features'],\n",
    "                     'Label': choose_max_prob_hub(doc['Features'], doc['Labels'])}). \\\n",
    "    map(unvectorize_data). \\\n",
    "    map(json.dumps). \\\n",
    "    repartition(6). \\\n",
    "    saveAsTextFile('hdfs://master:54310/single-label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
