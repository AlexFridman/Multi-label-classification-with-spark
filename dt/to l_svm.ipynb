{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pyspark.mllib.util import MLUtils\n",
    "from collections import Counter\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.classification import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_bi_tri_gramms(doc):\n",
    "    words = doc['Features']\n",
    "    bigramms = ['{} {}'.format(w_0, w_1) for w_0, w_1 in zip(words[:-1], words[1:])]\n",
    "    trigramms = ['{} {} {}'.format(w_0, w_1, w_2) for w_0, w_1, w_2 in zip(words[:-2], words[1:-1], words[2:])]\n",
    "    doc['Features'].extend(bigramms)\n",
    "    doc['Features'].extend(trigramms)\n",
    "    return doc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_data = sc.textFile('hdfs://master:54310/exp_f/clean') \\\n",
    "    .map(json.loads).map(add_bi_tri_gramms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_WL = temp_data.flatMap(lambda x: set(x['Features'])) \\\n",
    "    .map(lambda w: (w, 1)) \\\n",
    "    .reduceByKey(int.__add__) \\\n",
    "    .filter(lambda wc: wc[1] > 24) \\\n",
    "    .map(lambda wc: wc[0])  \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226119"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_WL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_WL_br = sc.broadcast(set(word_WL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_words(doc):\n",
    "    doc['Features'] = [w for w in doc['Features'] if w in word_WL_br.value]\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_rdd = temp_data.map(filter_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_idx = clean_rdd.flatMap(lambda x: x['Features']) \\\n",
    "    .distinct() \\\n",
    "    .zipWithIndex() \\\n",
    "    .collectAsMap()\n",
    "    \n",
    "label_idx = clean_rdd.flatMap(lambda x: x['Labels']) \\\n",
    "    .distinct() \\\n",
    "    .zipWithIndex() \\\n",
    "    .collectAsMap()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/home/hadoop/data/model/w_idx.json', 'w+') as fp:\n",
    "    json.dump(word_idx, fp)\n",
    "    \n",
    "with open('/home/hadoop/data/model/l_idx.json', 'w+') as fp:\n",
    "    json.dump(label_idx, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_idx_br = sc.broadcast(word_idx)\n",
    "label_idx_br = sc.broadcast(label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_num = len(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_l_points(x):\n",
    "    word_count = Counter(x['Features'])\n",
    "    feature_vect = Vectors.sparse(feature_num, [(word_idx_br.value[w], c) for w,c in word_count.items()])\n",
    "    label_idxs = [label_idx_br.value[l] for l in x['Labels']]\n",
    "    return [LabeledPoint(l, feature_vect) for l in label_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_points_rdd = clean_rdd.flatMap(to_l_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLUtils.saveAsLibSVMFile(l_points_rdd.repartition(1), 'hdfs://master:54310/exp_f/l_svm_b_t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
