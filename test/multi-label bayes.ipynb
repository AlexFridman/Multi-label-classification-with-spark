{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.common import callMLlibFunc, callJavaFunc\n",
    "from pyspark.mllib.classification import LabeledPoint\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayesModel\n",
    "from pyspark.mllib.linalg import _convert_to_vector\n",
    "from pyspark import RDD\n",
    "\n",
    "class MLNaiveBayesModel(NaiveBayesModel):\n",
    "    def predict_all(self, x):\n",
    "        if isinstance(x, RDD):\n",
    "            return x.map(lambda v: self.predict_all(v))\n",
    "        x = _convert_to_vector(x)\n",
    "        return list(zip(self.labels,self.pi + x.dot(self.theta.transpose())))\n",
    "    \n",
    "    def predict_n(self, x, n):\n",
    "        if isinstance(x, RDD):\n",
    "            return x.map(lambda v: self.predict_n(v), n)\n",
    "        return [int(l) for l,p in sorted(self.predict_all(x), key=lambda x: x[1], reverse=True)[:n]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RDD (labels) (features)\n",
    "def train_model(data, l = 1.0):\n",
    "    aggreagated = data.flatMap(lambda x: [(l, x[1]) for l in x[0]]). \\\n",
    "        combineByKey(lambda v: (1, v),\n",
    "                 lambda c, v: (c[0] + 1, c[1] + v),\n",
    "                 lambda c1, c2: (c1[0] + c2[0], c1[1] + c2[1])). \\\n",
    "        sortBy(lambda x: x[0]). \\\n",
    "        collect()\n",
    "    num_labels = len(aggreagated)\n",
    "    num_documents = data.count()\n",
    "    num_features = aggreagated[0][1][1].array.size\n",
    "    labels = np.zeros(num_labels)\n",
    "    pi = np.zeros(num_labels)\n",
    "    theta = np.zeros((num_labels, num_features))\n",
    "    pi_log_denom = math.log(num_documents + num_labels * l)\n",
    "    i = 0\n",
    "    for (label, (n, sum_term_freq)) in aggreagated:\n",
    "        labels[i] = label\n",
    "        pi[i] = math.log(n + l) - pi_log_denom\n",
    "        theta_log_denom = math.log(sum_term_freq.toArray().sum() + num_features * l)\n",
    "        for j in range(num_features):\n",
    "            theta[i,j] = math.log(sum_term_freq[j] + l) - theta_log_denom\n",
    "        i += 1  \n",
    "    return MLNaiveBayesModel(labels, pi, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = sc.textFile('hdfs://master:54310/new_lables3'). \\\n",
    "    map(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_idx = data.flatMap(lambda x: set(x['Features'])). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Id', 'Features', 'Labels'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_idx = data.flatMap(lambda x: x['Labels']). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_words(words: list):\n",
    "    word_counts = Counter([word_idx[w] for w in words])\n",
    "    return Vectors.sparse(num_features, word_counts.items())\n",
    "\n",
    "def vectorize_data(x: dict):\n",
    "    features = vectorize_words(x['Features'])\n",
    "    labels = [label_idx[l] for l in x['Labels']]\n",
    "    return (labels, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data = data.map(lambda x: vectorize_data(x)). \\\n",
    "    map(lambda x: (x[0], Vectors.dense(x[1].toArray())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = train_model(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22453"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1 = clean_data.filter(lambda x: len(x[0]) > 1)\n",
    "part1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36743"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.repartition(12).map(lambda x: (x[0], int(m.predict(x[1])))). \\\n",
    "    filter(lambda x: x[1] in x[0]). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39119"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266865"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: int(x['Id'])).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Честный эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = clean_data.randomSplit([0.7, 0.3], seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = train_model(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11570"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.repartition(12).map(lambda x: (set(x[0]), set(model.predict_n(x[1], 5)))). \\\n",
    "    filter(lambda x: len(x[1].intersection(x[0])) > 0). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13151"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def hold_out(data, k):\n",
    "    data_count = data.count()\n",
    "    print('data count', data_count)\n",
    "    partition_num = data.getNumPartitions()\n",
    "    # shuffle\n",
    "    idxs = list(range(data_count))\n",
    "    random.shuffle(idxs)\n",
    "    idxs_rdd = sc.parallelize(idxs).repartition(partition_num)\n",
    "    shuffled = idxs_rdd.keyBy(lambda x: x).join(data.zipWithIndex().map(lambda x: (x[1], x[0]))). \\\n",
    "        sortByKey().map(lambda x: x[1][1])\n",
    "    \n",
    "    sum_of_pred_accurace = 0\n",
    "    \n",
    "    h = data_count // k\n",
    "    idxs = range(0, data_count, h)\n",
    "    print(list(idxs))\n",
    "    indexed_data = shuffled.zipWithIndex()\n",
    "    indexed_data.cache()\n",
    "    for i, (l,r) in enumerate(zip(idxs, idxs[1:])):\n",
    "        print('#' + str(i))\n",
    "        print('l:',l,'r:',r)\n",
    "        test = indexed_data.filter(lambda x: l <= x[1] < r).map(lambda x: x[0])\n",
    "        training = indexed_data.filter(lambda x: x[1] < l or x[1] >= r).map(lambda x: x[0])\n",
    "        \n",
    "        model = train_model(training)\n",
    "        predictionAndLabels = test.map(lambda p: (model.predict_n(p[1], 3), p[0]))\n",
    "        accurace = 1.0 * predictionAndLabels.filter(lambda x: len(set(x[1]).intersection(set(x[0]))) > 0). \\\n",
    "                                            count() / (r - l) * 100\n",
    "        print(accurace)\n",
    "        sum_of_pred_accurace += accurace\n",
    "    result = sum_of_pred_accurace / k\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count 39119\n",
      "[0, 7823, 15646, 23469, 31292, 39115]\n",
      "#0\n",
      "l: 0 r: 7823\n",
      "83.35676850313179\n",
      "#1\n",
      "l: 7823 r: 15646\n",
      "83.97034385785504\n",
      "#2\n",
      "l: 15646 r: 23469\n",
      "83.7913843793941\n",
      "#3\n",
      "l: 23469 r: 31292\n",
      "83.45903106225234\n",
      "#4\n",
      "l: 31292 r: 39115\n",
      "83.33120286335165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.58174613319697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out(clean_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
