{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.linalg import Vectors\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayesModel\n",
    "from pyspark.mllib.linalg import _convert_to_vector\n",
    "from pyspark import RDD\n",
    "\n",
    "def scale(x: np.ndarray):\n",
    "    mean_x = x.mean()\n",
    "    max_x = x.max()\n",
    "    min_x = x.min()\n",
    "    return (x - min_x) / (max_x - min_x)\n",
    "\n",
    "class MLNaiveBayesModel(NaiveBayesModel):\n",
    "    def predict_all(self, x):\n",
    "        if isinstance(x, RDD):\n",
    "            return x.map(lambda v: self.predict_all(v))\n",
    "        x = _convert_to_vector(x)\n",
    "        log_probs = self.pi + x.dot(self.theta.transpose())\n",
    "        scaled_log_probs = scale(log_probs)\n",
    "        int_lables = [int(l_i) for l_i in self.labels]\n",
    "        labels_and_log_probs = zip(int_lables, scaled_log_probs)\n",
    "        return sorted(labels_and_log_probs, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "MultilabledPoint = namedtuple('MultilabledPoint', ['lables', 'features'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultilabledPoint:\n",
    "    def __init__(self, lables, features):\n",
    "        self.lables = lables\n",
    "        self.features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RDD (labels) (features)\n",
    "def train_model(data, l = 1.0):\n",
    "    aggreagated = data.flatMap(lambda x: [(l, x[1]) for l in x[0]]). \\\n",
    "        combineByKey(lambda v: (1, v),\n",
    "                 lambda c, v: (c[0] + 1, c[1] + v),\n",
    "                 lambda c1, c2: (c1[0] + c2[0], c1[1] + c2[1])). \\\n",
    "        sortBy(lambda x: x[0]). \\\n",
    "        collect()\n",
    "    num_labels = len(aggreagated)\n",
    "    num_documents = data.count()\n",
    "    num_features = aggreagated[0][1][1].array.size\n",
    "    labels = np.zeros(num_labels)\n",
    "    pi = np.zeros(num_labels, dtype=int)\n",
    "    theta = np.zeros((num_labels, num_features))\n",
    "    pi_log_denom = math.log(num_documents + num_labels * l)\n",
    "    i = 0\n",
    "    for (label, (n, sum_term_freq)) in aggreagated:\n",
    "        labels[i] = label\n",
    "        pi[i] = math.log(n + l) - pi_log_denom\n",
    "        theta_log_denom = math.log(sum_term_freq.toArray().sum() + num_features * l)\n",
    "        for j in range(num_features):\n",
    "            theta[i,j] = math.log(sum_term_freq[j] + l) - theta_log_denom\n",
    "        i += 1  \n",
    "    return MLNaiveBayesModel(labels, pi, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "data = sc.textFile('hdfs://master:54310/new_lables3'). \\\n",
    "    map(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_idx = data.flatMap(lambda x: set(x['Features'])). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Id', 'Features', 'Labels'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(1)[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "label_idx = data.flatMap(lambda x: x['Labels']). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def vectorize_words(words: list):\n",
    "    word_counts = Counter([word_idx[w] for w in words])\n",
    "    return Vectors.sparse(num_features, word_counts.items())\n",
    "\n",
    "def vectorize_data(x: dict):\n",
    "    features = vectorize_words(x['Features'])\n",
    "    lables = [label_idx[l] for l in x['Labels']]\n",
    "    return (lables, Vectors.dense(features.toArray()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_data = data.map(vectorize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36743"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.repartition(12).map(lambda x: (x[0], int(m.predict(x[1])))). \\\n",
    "    filter(lambda x: x[1] in x[0]). \\\n",
    "    count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39119"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266865"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.map(lambda x: int(x['Id'])).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Честный эксперимент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training, test = clean_data.randomSplit([0.7, 0.3], seed=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = train_model(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_model(model):\n",
    "    return MLNaiveBayesModel(model.labels, model.pi, model.theta)\n",
    "\n",
    "new_model = update_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.6923076923077"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(p, model):\n",
    "    lables = p[0]\n",
    "    features = p[1]\n",
    "    prediction = model.predict_all(features)[:3]\n",
    "    pred_lables = [l for l,w in prediction]\n",
    "    return (set(lables), set(pred_lables))\n",
    "    \n",
    "test.sample(True, 0.1, seed=0). \\\n",
    "    map(lambda p: predict(p, model)). \\\n",
    "    filter(lambda x: len(x[1].intersection(x[0])) > 0). \\\n",
    "    count() / test.sample(True, 0.1, seed=0).count() * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([78, 356, 736],\n",
       "  [(356, 1.0),\n",
       "   (598, 0.92654447339747259),\n",
       "   (581, 0.88540524476127247),\n",
       "   (0, 0.87720416501301546),\n",
       "   (456, 0.80356100547688381),\n",
       "   (419, 0.76109548746825673),\n",
       "   (14, 0.75507679650700554),\n",
       "   (495, 0.74542706876345788),\n",
       "   (521, 0.73420304065459474),\n",
       "   (385, 0.7289780541300076)])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.parallelize(test.take(1)).map(lambda x: (x[0], model.predict_all2(x[1])[:10])).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pi = model.pi\n",
    "theta = model.theta\n",
    "labels = model.labels\n",
    "def create_model():\n",
    "    return MLNaiveBayesModel(labels,pi,theta)\n",
    "tM = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(612.0, 0.040052240826358991),\n",
       " (554.0, 0.039637278302299933),\n",
       " (273.0, 0.038522293503595047),\n",
       " (424.0, 0.037150267510892017),\n",
       " (370.0, 0.037077360223540773),\n",
       " (401.0, 0.036049647411316846),\n",
       " (186.0, 0.034987988025660041),\n",
       " (47.0, 0.034329014311766902),\n",
       " (813.0, 0.034097259062080623),\n",
       " (841.0, 0.033965041958208063),\n",
       " (771.0, 0.032399057752911589),\n",
       " (390.0, 0.031379267624089734),\n",
       " (440.0, 0.024585464938292962),\n",
       " (103.0, 0.022672843849451986),\n",
       " (752.0, 0.014863573462702419),\n",
       " (202.0, 0.0099958485328929449),\n",
       " (241.0, 0.0093664731812346923),\n",
       " (714.0, 0.0)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tM.predict_all(test.take(1)[0][1])[860:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Hold Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def hold_out(data, k):\n",
    "    data_count = data.count()\n",
    "    print('data count', data_count)\n",
    "    partition_num = data.getNumPartitions()\n",
    "    # shuffle\n",
    "    idxs = list(range(data_count))\n",
    "    random.shuffle(idxs)\n",
    "    idxs_rdd = sc.parallelize(idxs).repartition(partition_num)\n",
    "    shuffled = idxs_rdd.keyBy(lambda x: x).join(data.zipWithIndex().map(lambda x: (x[1], x[0]))). \\\n",
    "        sortByKey().map(lambda x: x[1][1])\n",
    "    \n",
    "    sum_of_pred_accurace = 0\n",
    "    \n",
    "    h = data_count // k\n",
    "    idxs = range(0, data_count, h)\n",
    "    print(list(idxs))\n",
    "    indexed_data = shuffled.zipWithIndex()\n",
    "    indexed_data.cache()\n",
    "    for i, (l,r) in enumerate(zip(idxs, idxs[1:])):\n",
    "        print('#' + str(i))\n",
    "        print('l:',l,'r:',r)\n",
    "        test = indexed_data.filter(lambda x: l <= x[1] < r).map(lambda x: x[0])\n",
    "        training = indexed_data.filter(lambda x: x[1] < l or x[1] >= r).map(lambda x: x[0])\n",
    "        \n",
    "        model = train_model(training)\n",
    "        predictionAndLabels = test.map(lambda p: (model.predict_n(p[1], 3), p[0]))\n",
    "        accurace = 1.0 * predictionAndLabels.filter(lambda x: len(set(x[1]).intersection(set(x[0]))) > 0). \\\n",
    "                                            count() / (r - l) * 100\n",
    "        print(accurace)\n",
    "        sum_of_pred_accurace += accurace\n",
    "    result = sum_of_pred_accurace / k\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count 39119\n",
      "[0, 7823, 15646, 23469, 31292, 39115]\n",
      "#0\n",
      "l: 0 r: 7823\n",
      "83.35676850313179\n",
      "#1\n",
      "l: 7823 r: 15646\n",
      "83.97034385785504\n",
      "#2\n",
      "l: 15646 r: 23469\n",
      "83.7913843793941\n",
      "#3\n",
      "l: 23469 r: 31292\n",
      "83.45903106225234\n",
      "#4\n",
      "l: 31292 r: 39115\n",
      "83.33120286335165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "83.58174613319697"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hold_out(clean_data, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
