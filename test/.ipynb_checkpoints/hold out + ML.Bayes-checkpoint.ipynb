{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple, Counter\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import RDD\n",
    "\n",
    "def shuffle_and_split(data: RDD, fold_n: int, seed = 0):\n",
    "    fold_weights = [1 / fold_n] * fold_n\n",
    "    return data.randomSplit(fold_weights)\n",
    "\n",
    "def hold_out(sc, data: RDD, k: int, model_builder, metrics: list):\n",
    "    folds = shuffle_and_split(data, k)\n",
    "    for i in range(k):\n",
    "        test = folds[i]\n",
    "        training = sc.union(folds[:i] + folds[i + 1:])\n",
    "        model = model_builder(training)\n",
    "        lables_and_predictions = test.map(lambda x: (x['lables'], model.predict_all(x['features'])))\n",
    "        for metric in metrics:\n",
    "            metric.evaluate(lables_and_predictions)\n",
    "    return metrics\n",
    "\n",
    "from pyspark import RDD\n",
    "\n",
    "class Metric:\n",
    "    def __init__(self, name: str, verbose=False):\n",
    "        self._name = name\n",
    "        self._results = []\n",
    "        self._verbose = verbose\n",
    "        \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self._name\n",
    "    \n",
    "    @property\n",
    "    def results(self):\n",
    "        return self._results\n",
    "    \n",
    "    @property\n",
    "    def avg(self):\n",
    "        return np.average(_results)\n",
    "    \n",
    "    def evaluate(self, lables, predictions):\n",
    "        pass\n",
    "\n",
    "class AccuracyMetric(Metric):\n",
    "    def __init__(self, pred_n: int, intersect_n: int):\n",
    "        self._pred_n = pred_n\n",
    "        self._intersect_n = intersect_n\n",
    "        super(AccuracyMetric, self).__init__(name='Accuracy', verbose=False)\n",
    "        \n",
    "    def evaluate(self, lables_and_predictions: RDD):\n",
    "        TP = lables_and_predictions.map(lambda x:\n",
    "                                    (set(x[0]), set([p for p,w in x[1][:self._pred_n]]))). \\\n",
    "                                    filter(lambda x:\n",
    "                                           len(x[0].intersection(x[1])) > self._intersect_n)\n",
    "        accuracy = 100.0 * TP.count() / lables_and_predictions.count()\n",
    "        if self._verbose:\n",
    "            print('accuracy: ', accuracy)\n",
    "        self._results.append(accuracy)\n",
    "        return accuracy\n",
    "\n",
    "from pyspark.mllib.classification import NaiveBayesModel\n",
    "from pyspark.mllib.linalg import _convert_to_vector\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark import RDD\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def scale(x: np.ndarray):\n",
    "    mean_x = x.mean()\n",
    "    max_x = x.max()\n",
    "    min_x = x.min()\n",
    "    return (x - min_x) / (max_x - min_x)\n",
    "\n",
    "class MLNaiveBayesModel(NaiveBayesModel):\n",
    "    def predict_all(self, x):\n",
    "        if isinstance(x, RDD):\n",
    "            return x.map(lambda v: self.predict_all(v))\n",
    "        x = _convert_to_vector(x)\n",
    "        log_probs = self.pi + x.dot(self.theta.transpose())\n",
    "        scaled_log_probs = scale(log_probs)\n",
    "        int_lables = [int(l_i) for l_i in self.labels]\n",
    "        labels_and_log_probs = zip(int_lables, scaled_log_probs)\n",
    "        return sorted(labels_and_log_probs, key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "# RDD (labels) (features)\n",
    "def train_model(data, l = 1.0):\n",
    "    aggreagated = data.flatMap(lambda x: [(l, x['features']) for l in x['lables']]). \\\n",
    "        combineByKey(lambda v: (1, v),\n",
    "                 lambda c, v: (c[0] + 1, c[1] + v),\n",
    "                 lambda c1, c2: (c1[0] + c2[0], c1[1] + c2[1])). \\\n",
    "        sortBy(lambda x: x[0]). \\\n",
    "        collect()\n",
    "    num_labels = len(aggreagated)\n",
    "    num_documents = data.count()\n",
    "    num_features = aggreagated[0][1][1].array.size\n",
    "    labels = np.zeros(num_labels)\n",
    "    pi = np.zeros(num_labels, dtype=int)\n",
    "    theta = np.zeros((num_labels, num_features))\n",
    "    pi_log_denom = math.log(num_documents + num_labels * l)\n",
    "    i = 0\n",
    "    for (label, (n, sum_term_freq)) in aggreagated:\n",
    "        labels[i] = label\n",
    "        pi[i] = math.log(n + l) - pi_log_denom\n",
    "        theta_log_denom = math.log(sum_term_freq.toArray().sum() + num_features * l)\n",
    "        for j in range(num_features):\n",
    "            theta[i,j] = math.log(sum_term_freq[j] + l) - theta_log_denom\n",
    "        i += 1  \n",
    "    return MLNaiveBayesModel(labels, pi, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MultilabledPoint = namedtuple('MultilabledPoint',\n",
    "                              ['lables', 'features'], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MultilabledPoint(object):\n",
    "    def __init__(self, lables, features):\n",
    "        self.lables = lables\n",
    "        self.features = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = sc.textFile('hdfs://master:54310/test3').map(json.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_idx = raw_data.flatMap(lambda x: set(x['Features'])). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()\n",
    "label_idx = raw_data.flatMap(lambda x: x['Labels']). \\\n",
    "    distinct(). \\\n",
    "    zipWithIndex(). \\\n",
    "    collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = len(word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_words(words: list):\n",
    "    word_counts = Counter([word_idx[w] for w in words])\n",
    "    return Vectors.sparse(num_features, word_counts.items())\n",
    "\n",
    "def vectorize_data(x: dict):\n",
    "    features = vectorize_words(x['Features'])\n",
    "    lables = [label_idx[l] for l in x['Labels']]\n",
    "    return {'lables':lables, 'features':Vectors.dense(features.toArray())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = raw_data.map(vectorize_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = hold_out(sc, data, 2, train_model, [AccuracyMetric(3, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38.60060090645211, 38.65106251924854]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = train_model(data.zipWithIndex().filter(lambda x: x[1] < 1000). \\\n",
    "                   map(lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = data.zipWithIndex().filter(lambda x: x[1] < 1). \\\n",
    "    map(lambda x: x[0]). \\\n",
    "    map(lambda x: (x['lables'],\n",
    "        model.predict_all(x['features'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AccuracyMetric(3,1).evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
